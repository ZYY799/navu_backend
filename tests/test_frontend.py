"""
å‰ç«¯é›†æˆæµ‹è¯•
æ¨¡æ‹Ÿå‰ç«¯å‘é€: å½“å‰ä½ç½® + è¯­éŸ³æ–‡å­— + å›¾ç‰‡
"""
import asyncio
import base64
import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))


async def frontend_integration_test():
    """æ¨¡æ‹Ÿå‰ç«¯å®Œæ•´è°ƒç”¨æµç¨‹"""

    from app.services.tts_service import TTSService
    from app.services.yolo_service import YOLOService
    from app.services.llm_service import LLMService
    from app.core.session_manager import session_manager

    print("=" * 80)
    print("å‰ç«¯é›†æˆæµ‹è¯•")
    print("=" * 80)

    # ============================================================
    # å‰ç«¯è¾“å…¥ (æ¨¡æ‹Ÿå‰ç«¯ä¼ æ¥çš„ä¸‰ä¸ªå˜é‡)
    # ============================================================

    # 1. å½“å‰ä½ç½®
    current_location = {
        "lat": 39.916527,
        "lng": 116.397128
    }

    # 2. è¯­éŸ³è¯†åˆ«åçš„æ–‡å­—
    voice_text = "æˆ‘æƒ³å»æ•…å®«"

    # 3. æ‘„åƒå¤´æ‹æ‘„çš„å›¾ç‰‡ (Base64ç¼–ç )
    image_path = "fig/R-C.jpg"
    if os.path.exists(image_path):
        with open(image_path, 'rb') as f:
            image_bytes = f.read()
            image_base64 = base64.b64encode(image_bytes).decode('utf-8')
    else:
        print(f"âŒ æµ‹è¯•å›¾ç‰‡ä¸å­˜åœ¨: {image_path}")
        return

    print("\nğŸ“¥ å‰ç«¯è¾“å…¥:")
    print(f"  ä½ç½®: lat={current_location['lat']}, lng={current_location['lng']}")
    print(f"  æ–‡å­—: {voice_text}")
    print(f"  å›¾ç‰‡: {image_path} (å·²è½¬Base64)")

    # ============================================================
    # åç«¯å¤„ç†æµç¨‹
    # ============================================================

    print("\n" + "=" * 80)
    print("åç«¯å¤„ç†")
    print("=" * 80)

    # æ­¥éª¤1: éšœç¢ç‰©æ£€æµ‹
    print("\nğŸ” [1/3] YOLOéšœç¢ç‰©æ£€æµ‹...")
    yolo_service = YOLOService()
    detection_results = await yolo_service.detect_batch([image_base64])
    obstacles = yolo_service.aggregate_obstacles(detection_results)
    safety_level = yolo_service.calculate_safety_level(obstacles)

    print(f"  âœ… æ£€æµ‹åˆ° {len(obstacles)} ä¸ªéšœç¢ç‰©")
    print(f"  âœ… å®‰å…¨ç­‰çº§: {safety_level}/5")
    if obstacles:
        for i, obs in enumerate(obstacles[:3], 1):
            print(f"     {i}. {obs.type} - {obs.distance}m - {obs.direction}")

    # æ­¥éª¤2: LLMç†è§£ç”¨æˆ·æ„å›¾
    print("\nğŸ¤– [2/3] LLMç†è§£ç”¨æˆ·éœ€æ±‚...")
    llm_service = LLMService()
    session = session_manager.create_conversation("test_user", "test_session")

    # æ„é€ å®Œæ•´æ¶ˆæ¯ (åŒ…å«ä½ç½®ä¸Šä¸‹æ–‡)
    full_message = f"ç”¨æˆ·å½“å‰ä½ç½®: {current_location['lat']}, {current_location['lng']}\nç”¨æˆ·è¯´: {voice_text}"
    llm_response = await llm_service.process_conversation(full_message, session)

    print(f"  âœ… LLMå›å¤: {llm_response['reply'][:80]}...")
    print(f"  âœ… å¯¼èˆªçŠ¶æ€: {llm_response['nav_state']}")

    # æ­¥éª¤3: ç”Ÿæˆè¯­éŸ³å›å¤
    print("\nğŸ”Š [3/3] ç”ŸæˆTTSè¯­éŸ³...")
    tts_service = TTSService()

    # ç»„åˆæœ€ç»ˆå›å¤ (éšœç¢ç‰©è­¦å‘Š + LLMå›å¤)
    if obstacles:
        warning = yolo_service.generate_warning_text(obstacles)
        final_reply = f"{warning}ã€‚{llm_response['reply']}"
    else:
        final_reply = llm_response['reply']

    audio_url = await tts_service.text_to_speech(final_reply, "test_session")
    print(f"  âœ… éŸ³é¢‘æ–‡ä»¶: {audio_url}")

    # ============================================================
    # åç«¯è¿”å›ç»“æœ (å‰ç«¯æ¥æ”¶)
    # ============================================================

    print("\n" + "=" * 80)
    print("ğŸ“¤ åç«¯è¿”å› (å‰ç«¯æ¥æ”¶)")
    print("=" * 80)

    backend_response = {
        "success": True,
        "message": final_reply,
        "audioUrl": audio_url,
        "obstacles": [
            {
                "type": obs.type,
                "distance": obs.distance,
                "direction": obs.direction,
                "confidence": obs.confidence
            }
            for obs in obstacles
        ],
        "safetyLevel": safety_level,
        "navState": llm_response['nav_state'],
        "navData": llm_response.get('data', {})
    }

    print(f"\n  success: {backend_response['success']}")
    print(f"  message: {backend_response['message']}")
    print(f"  audioUrl: {backend_response['audioUrl']}")
    print(f"  obstacles: {len(backend_response['obstacles'])} ä¸ª")
    print(f"  safetyLevel: {backend_response['safetyLevel']}/5")
    print(f"  navState: {backend_response['navState']}")

    print("\n" + "=" * 80)
    print("âœ… æµ‹è¯•å®Œæˆ")
    print("=" * 80)

    return backend_response


if __name__ == "__main__":
    result = asyncio.run(frontend_integration_test())
